{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 1 - Parte 2\n",
    "\n",
    "### Regresión logística y Funciones Discriminantes Gausianas\n",
    "\n",
    "### 2018-II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En este archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haga click en el siguiente enlace para autenticarse con su cuenta de correo institucional\n",
      "https://accounts.google.com/o/oauth2/auth?client_id=893762525034-g9d91ddls9e19a1q77c7hsq2rhgqo9h7.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080&scope=profile+email&access_type=offline&response_type=code\n",
      "waiting for authentication ...\n",
      "authentication succeeded\n",
      "/?code=4/OgD0uHHE95Szd9-UfT2oiUpPDx1JDCZsV3nx07mCyzurpc46Qyn-eV1oiK0t5MwlZfoXRGiJV0b2otypBTSYcCA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='https://lh6.googleusercontent.com/-IyRKvwiEzoA/AAAAAAAAAAI/AAAAAAAAACo/XBI96lqyxzU/photo.jpg' width=60 height=60/></td><td>johna.galeano@udea.edu.co<br/>JOHN   ALEXÁNDER GALEANO OSPINA<br/>google id: 111882263615850761169<br/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tomado de https://github.com/rramosp/mooc-grader\n",
    "from Autentication import *#python 3\n",
    "import inspect, urllib\n",
    "html, auth_code, userinfo = google_authenticate(PORT_NUMBER=8080)\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Segundo integrante: Sidney Paola Aguirre Castro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from __future__ import division\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "En este laboratorio se va a realizar un procedimiento análogo al del laboratorio anterior, pero con el modelo de regresión logística que sirve para resolver problemas de clasificación (en principio biclase).\n",
    "\n",
    "Analice los siguientes métodos a la luz de la teoría vista para el modelo de regresión logística. Una vez comprenda su funcionamiento proceda a completar el código del método de gradiente descendente con la regla de actualización de los parámetros\n",
    "\n",
    "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
    "\n",
    "Para el problema de clasificación. Tenga presente que si ya implementó la regla de actualización de parámetros para el modelo de regresión polinomial múltiple, este punto es trivial, ya que solo tiene que incluir la función sigmoidal tal como lo vimos en la teoría.\n",
    "\n",
    "Además se pide graficar el error de clasificación durante las iteraciones del algorítmo. La gráfica debe llevar título y los correspondientes nombres de los ejes.\n",
    "\n",
    "Nota: observe que el método logistic_regression ya hace el llamado a la función sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoidal\n",
    "def sigmoidal(z):\n",
    "    \n",
    "    #Complete la siguiente línea con el código para calcular la salida de la función sigmoidal\n",
    "    s = np.exp(z)/(1+np.exp(z))\n",
    "    \n",
    "    #Complete el código para realizar la gráfica de la función aquí\n",
    "    plt.plot(z,s)\n",
    "    plt.show()\n",
    "    return s\n",
    "\n",
    "\n",
    "#Modelo Regresión logística\n",
    "def logistic_regression(X, W):\n",
    "    Yest = np.dot(X,W)  #con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\n",
    "    Y_lest = sigmoidal(Yest)\n",
    "    \n",
    "    #Se llevan los valores a 1 o 0 para los que está definido el modelo de regresión logística\n",
    "    pos = 0\n",
    "    for tag in Y_lest:\n",
    "        \n",
    "        if tag > 0.5:\n",
    "            Y_lest[pos] = 1\n",
    "        elif tag < 0.5:\n",
    "            Y_lest[pos] = 0\n",
    "        \n",
    "        pos += 1\n",
    "    \n",
    "    return Y_lest    #Esta variable contiene la salida de sigm(f(X,W))\n",
    "\n",
    "\n",
    "#Potencia de polinomio (En es laboratorio solo trabajaremos el caso lineal (grado 1), pero se pueden probar otras fronteras)\n",
    "def potenciaPolinomio(X,grado):\n",
    "    X2 = X\n",
    "    \n",
    "    if grado != 1:\n",
    "        for i in range(2,grado+1):\n",
    "            Xadd = X**i\n",
    "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
    "    \n",
    "    return X2\n",
    "\n",
    "\n",
    "#Para calcular el error del modelo de regresión logística\n",
    "def error_logistic(Y_lest, Y):\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    \n",
    "    error = error/np.size(Y)\n",
    "    \n",
    "    #print \"La eficiencia en esta iteración fue: \"+str(1-error)+'\\n'\n",
    "    \n",
    "    return error\n",
    "\n",
    "#Gradiente descendente para regresión logística\n",
    "def gradiente_descendente_logistic(X,Y,grado,eta):\n",
    "    \n",
    "    #X es la matriz de datos extendida. W es el vector de parámetros del modelo\n",
    "    #Extendemos la matriz\n",
    "    unos = np.array([np.ones(np.size(X,0))])\n",
    "    #Concatenar el vector de unos con la matriz X\n",
    "    X = np.concatenate((unos.T, X), axis=1)\n",
    "    X = X.reshape(np.size(X,0),np.size(X,1))\n",
    "    \n",
    "    Y = Y.reshape(np.size(Y), 1)\n",
    "    \n",
    "    #Tomamos el número de variables del problema\n",
    "    d = np.size(X,1)\n",
    "\n",
    "    #Tomamos el número de muestras de la base de datos\n",
    "    N = np.size(X,0)\n",
    "    \n",
    "    #Inicializamos el vector de parámetros aleatoriamente\n",
    "    #Want = np.random.randn(d)\n",
    "    W = np.zeros(d)\n",
    "    W = W.reshape(np.size(W),1)\n",
    "\n",
    "    eta = eta\n",
    "    \n",
    "    iteraciones = 1000\n",
    "    errores = np.zeros(iteraciones)\n",
    "    \n",
    "    for iter in range(iteraciones):\n",
    "\n",
    "        Y_estimado = logistic_regression(X,W)\n",
    "        #Error en clasificación\n",
    "        error = error_logistic(Y_estimado,Y)\n",
    "        errores[iter] = error\n",
    "\n",
    "        #Aquí debe completar el código con la regla de actualización de los parámetros W para regresión\n",
    "        #logística. Tenga en cuenta los nombres de las variables ya creadas: Want, X, Y\n",
    "        for j in range(d):\n",
    "             W[j] = W[j] - (eta * ((logistic_regression(X,W).T-Y[i])) * X[:,j])\n",
    "    \n",
    "    #Aquí debe completar el código para realizar la gráfica del error de clasificación vs. iteraciones\n",
    "    \n",
    "    plt.title('Error de clasificación Vs Iteraciones')\n",
    "    plt.ylabel('Error de clasificación')\n",
    "    plt.xlabel('iteraciones')\n",
    "    plt.ylim(0,1000)\n",
    "    plt.xlim(0,600)\n",
    "    plt.ion()\n",
    "    plt.plot(np.linspace(0,iteraciones,iteraciones),error)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print('Vector de parámetros del modelo:\\n') \n",
    "    print (W)\n",
    "    print ('\\nError de entrenamiento = ' + str(errores[-1]))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "A continuación se leen los datos de un problema de clasificación. Las variables o caracterísicas son guardadas en la variable X y la variable de salida es guardada en la variable Y. Grafique los datos usando la funci&oacute;n scatter de matplotlib y responda a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DB/DatosClases.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DB/DatosClases.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3726dcd89038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DB/DatosClases.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Muestras x características\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Variable de salida\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxuni\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mbyte_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DB/DatosClases.mat'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('DB/DatosClases.mat')\n",
    "X = mat['X'] # Muestras x características\n",
    "Y = mat['Y'] #Variable de salida\n",
    "xuni = np.unique(X)\n",
    "clases= np.unique(Y)\n",
    "print(clases)\n",
    "tamx = np.size(X[:,1])\n",
    "print('Hay ' + str(tamx) + ' muestras')\n",
    "\n",
    "tamy = np.size(X[1,:])\n",
    "print('Hay ' + str(tamy) + 'caracteristicas')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Caracteristica 1')\n",
    "plt.ylabel('Caracteristica 2')\n",
    "plt.scatter(X[:,0], X[:,1],c=Y.flat, cmap=\"Accent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Cu&aacute;ntas clases tiene el problema?: \n",
    "R: El problema tiene 2 clases.\n",
    "\n",
    "2.2 Cu&aacute;ntas caracter&iacute;sticas tiene el problema?:\n",
    "R: El problema tiene 2 caracter&iacute;sticas.\n",
    "\n",
    "2.3 Cu&aacute;ntas muestras tiene el problema?:\n",
    "R: El problema tiene 500 muestras.\n",
    "\n",
    "2.4 El problema es linealmente separable?:\n",
    "R: El problema No es linealmente separable, puesto que no es posible separar las clases por medio de una l&iacute;nea. Las clases se distribuyen de una forma circular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Complete el código de la siguiente celda llamando el método gradiente_descendente_logistic y pasándole los parámetros correspondientes, de acuerdo con los parámetros que indica la tabla de resultados, ejecute el entrenamiento y llene la tabla de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,350) and (1,3) not aligned: 350 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f3b89bae2a83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#Complete la siguiente línea de código llamando el método gradiente_descendente con sus respectivos argumentos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradiente_descendente_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrado\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#Evaluamos las predicciones del modelo con los datos de test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-ebc958ded8c0>\u001b[0m in \u001b[0;36mgradiente_descendente_logistic\u001b[1;34m(X, Y, grado, eta)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m#logística. Tenga en cuenta los nombres de las variables ya creadas: Want, X, Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m              \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m#Aquí debe completar el código para realizar la gráfica del error de clasificación vs. iteraciones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-ebc958ded8c0>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m(X, W)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Modelo Regresión logística\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mYest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mY_lest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoidal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,350) and (1,3) not aligned: 350 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import math\n",
    "N = np.size(X,0)\n",
    "\n",
    "# #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n",
    "grado = 1\n",
    "X2 = potenciaPolinomio(X,grado)\n",
    "\n",
    "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
    "random.seed(1)\n",
    "ind=np.random.permutation(N)\n",
    "Xtrain = X2[ind[0:int(math.ceil(0.7*N))],:]\n",
    "Xtest = X2[ind[int(math.ceil(0.7*N)):N],:]\n",
    "Ytrain = Y[ind[0:int(math.ceil(0.7*N))]]\n",
    "Ytest = Y[ind[int(math.ceil(0.7*N)):N]]\n",
    "\n",
    "#Normalizamos los datos\n",
    "media = np.mean(Xtrain)\n",
    "desvia = np.std(Xtrain)\n",
    "Xtrain = stats.stats.zscore(Xtrain)\n",
    "Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "eta = 1\n",
    "\n",
    "#Complete la siguiente línea de código llamando el método gradiente_descendente con sus respectivos argumentos\n",
    "W = gradiente_descendente_logistic(Xtrain,Ytrain,grado,eta)\n",
    "\n",
    "#Evaluamos las predicciones del modelo con los datos de test\n",
    "unos = np.array([np.ones(np.size(Xtest,0))])\n",
    "Xtest2 = np.concatenate((unos.T, Xtest), axis=1)\n",
    "Xtest2 = Xtest2.reshape(np.size(Xtest2,0),np.size(Xtest2,1))\n",
    "Yest = logistic_regression(Xtest2, W)\n",
    "Error = error_logistic(Yest,Ytest)\n",
    "print('\\nError durante la prueba = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qgrid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c2c6ffabd420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mqgrid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mrandn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df_types = pd.DataFrame({\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qgrid'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Tasa de aprendizaje' : pd.Series(['1', '1', '1', '1', '1', '0.1', '0.1', '0.1', '0.1', '0.1', '0.001', '0.001', '0.001', '0.001', '0.001']),\n",
    "    'Grado del polinomio' : pd.Series([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])})\n",
    "df_types[\"Error_Entrenamiento\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types.set_index(['Tasa de aprendizaje','Grado del polinomio'], inplace=True)\n",
    "df_types[\"Error_Entrenamiento\"][2] = \"0.0\"\n",
    "df_types[\"Error_Prueba\"][2] = \"0.5\"\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error_Entrenamiento</th>\n",
       "      <th>Error_Prueba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasa de aprendizaje</th>\n",
       "      <th>Grado del polinomio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Error_Entrenamiento Error_Prueba\n",
       "Tasa de aprendizaje Grado del polinomio                                 \n",
       "1                   1                                                   \n",
       "                    2                                                   \n",
       "                    3                                   0.0          0.5\n",
       "                    4                                                   \n",
       "                    5                                                   \n",
       "0.1                 1                                                   \n",
       "                    2                                                   \n",
       "                    3                                                   \n",
       "                    4                                                   \n",
       "                    5                                                   \n",
       "0.001               1                                                   \n",
       "                    2                                                   \n",
       "                    3                                                   \n",
       "                    4                                                   \n",
       "                    5                                                   "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "4.1 Escriba el modelo $f(\\textbf{x},\\textbf{w})$, de la mejor frontera de decisión que encontró según la tabla de resultados.\n",
    "\n",
    "4.2 Basado en el valor del error obtenido, ¿cu&aacute;ntas muestras de entrenamiento y de prueba clasifica mal el modelo? (un valor para cada conjunto). Nota. Escriba en una celda el código con el cuál obtuvo la respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza un clasificador basado en Funciones Discriminantes Gaussianas para resolver el mismo problema de clasificación. Ejecute el código y responda las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistribucionGaussiana(X,Mu,Sigma):\n",
    "    \n",
    "    SigmaInversa = np.linalg.inv(np.array(Sigma))\n",
    "    PrimerTermino = (1/(2*math.pi*math.sqrt(np.linalg.det(Sigma))))\n",
    "    \n",
    "    primerDot = np.dot((X-Mu),SigmaInversa)\n",
    "    segundoDot = np.dot(primerDot,(X-Mu).T)\n",
    "    Exponencial = math.exp(-0.5*segundoDot)\n",
    "    \n",
    "    Probabilidad = PrimerTermino * Exponencial\n",
    "    \n",
    "    return Probabilidad\n",
    "\n",
    "def FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo):\n",
    "    \n",
    "    N = Xtest.shape[0]\n",
    "    #Estimación de medias y Covarianzas\n",
    "    Mu1 = np.mean(Xtrain[(Ytrain==1).flat,:], axis=0)\n",
    "    Mu2 = np.mean(Xtrain[(Ytrain==0).flat,:], axis=0)\n",
    "  \n",
    "    Sigma1 = np.cov((Xtrain[(Ytrain==1).flat,:]).T)\n",
    "    Sigma2 = np.cov((Xtrain[(Ytrain==0).flat,:]).T)\n",
    "    \n",
    "    Sigma3 = (0.5*(Sigma1+Sigma2))\n",
    "    Yest = np.zeros(N)\n",
    "    Tipo = tipo\n",
    "    for i in range(N):\n",
    "        \n",
    "            if Tipo == 0 :\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma1)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma2)\n",
    "            elif Tipo == 1:\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma3)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma3)\n",
    "            if p1 >= p2:\n",
    "                Yest[i] = 1\n",
    "            else:\n",
    "                Yest[i] = 0\n",
    "                \n",
    "    return Yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 0 # Frontera lineal\n",
    "Yest0 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest0,Ytest)\n",
    "print('\\nError prueba (Frontera Lineal) = ' + str(Error))\n",
    "\n",
    "\n",
    "tipo = 1 #Frontera cuadrática\n",
    "Yest1 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest1,Ytest)\n",
    "print('\\nError prueba (Frontera cuadrática) = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 ¿Cuál tipo de frontera proporcionó mejores resultados?:\n",
    "\n",
    "5.2 Teniendo en cuenta la forma de los datos (De acuerdo con la gráfica hecha en el punto 2), expliqué porqué el modelo de Funciones Discriminantes Gaussianas obtiene un buen resultado:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
