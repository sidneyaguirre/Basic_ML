{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 6 Parte 2\n",
    "\n",
    "### Reducción de dimensión por extracción de características con PCA y LDA\n",
    "\n",
    "### Universidad de Antioquia\n",
    "\n",
    "### Facultad de Ingeniería\n",
    "\n",
    "### Ingeniería de Sistemas\n",
    "\n",
    "### Ude@ - 2018-II\n",
    "\n",
    "#### Profesor: Antonio Tamayo Herrera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiantes\n",
    "\n",
    "**Nombre: Sidney Paola Aguirre Castro**\n",
    "\n",
    "**Céduda: 1114732514**\n",
    "\n",
    "**Nombre:John Alexander Galeano Ospina**\n",
    "\n",
    "**Cédula: 1036645341**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Este ejercicio tiene como objetivo implementar varias técnicas de extracción de características (PCA y LDA) y usar SVM para resolver un problema de clasificación multietiqueta o multiclase.\n",
    "\n",
    "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
    "\n",
    "#### Abstract: \n",
    "The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.\n",
    "\t\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "LB - FHR baseline (beats per minute)\n",
    "\n",
    "AC - # of accelerations per second\n",
    "\n",
    "FM - # of fetal movements per second\n",
    "\n",
    "UC - # of uterine contractions per second\n",
    "\n",
    "DL - # of light decelerations per second\n",
    "\n",
    "DS - # of severe decelerations per second\n",
    "\n",
    "DP - # of prolongued decelerations per second\n",
    "\n",
    "ASTV - percentage of time with abnormal short term variability\n",
    "\n",
    "MSTV - mean value of short term variability\n",
    "\n",
    "ALTV - percentage of time with abnormal long term variability\n",
    "\n",
    "MLTV - mean value of long term variability\n",
    "\n",
    "Width - width of FHR histogram\n",
    "\n",
    "Min - minimum of FHR histogram\n",
    "\n",
    "Max - Maximum of FHR histogram\n",
    "\n",
    "Nmax - # of histogram peaks\n",
    "\n",
    "Nzeros - # of histogram zeros\n",
    "\n",
    "Mode - histogram mode\n",
    "\n",
    "Mean - histogram mean\n",
    "\n",
    "Median - histogram median\n",
    "\n",
    "Variance - histogram variance\n",
    "\n",
    "Tendency - histogram tendency\n",
    "\n",
    "CLASS - FHR pattern class code (1 to 10)\n",
    "\n",
    "NSP - fetal state class code (N=normal (1); S=suspect (2); P=pathologic (3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar a ejecutar las celdas, debe tener instalada la librería mlxtend que usamos en la parte 1 del presente laboratorio. Si aún no la ha instalado, remítase a la guía del laboratorio anterior.\n",
    "\n",
    "Analice y comprenda la siguiente celda de código donde se importan las librerías a usar y se carga la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la base de datos de entrenamiento. dim de X: (2126, 22)\tdim de Y: (2126,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis as PCA\n",
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import time\n",
    "\n",
    "#cargamos la bd de entrenamiento\n",
    "db = np.loadtxt('DB_Fetal_Cardiotocograms.txt',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "X = db[:,0:22]\n",
    "\n",
    "#Solo para dar formato a algunas variables\n",
    "for i in range(1,7):\n",
    "    X[:,i] = X[:,i]*1000\n",
    "\n",
    "X = X\n",
    "Y = db[:,22]\n",
    "\n",
    "#Para darle formato de entero a la variable de salida\n",
    "\n",
    "Y_l = []\n",
    "for i in Y:\n",
    "    Y_l.append(int(i))\n",
    "Y = np.asarray(Y_l)\n",
    "\n",
    "print (\"Dimensiones de la base de datos de entrenamiento. dim de X: \" + str(np.shape(X)) + \"\\tdim de Y: \" + str(np.shape(Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda de código no tiene que completar nada. Analice, comprenda y ejecute el código y tenga en cuenta los resultados para completar la tabla que se le pide más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación sin aplicar extracción: 0.07712817787226504 +/- 0.05442325724156325\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 92.2871822127735%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.4718360900878906 segundos.\n"
     ]
    }
   ],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Creamos el clasificador SVM. Tenga en cuenta que el problema es multiclase. \n",
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "#Implemetamos la metodología de validación\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "    #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "\n",
    "print(\"\\nError de validación sin aplicar extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "print(\"\\nEficiencia en validación aplicando extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación sin aplicar extracción: 0.07336566569226681 +/- 0.04323363786595027\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.4568498134613037 segundos.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Creamos el clasificador SVM. Tenga en cuenta que el problema es multiclase. \n",
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "#Implemetamos la metodología de validación\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "    \n",
    "     #Normalizamos los datos\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "\n",
    "print(\"\\nError de validación sin aplicar extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "1.1 Al aplicar PCA es necesario estandarizar los datos? Si, No y por qué? En qué consiste dicha estandarización?\n",
    "\n",
    "R/:Si,La normalización es signifcativa en PCA ya que es un ejercicio que maximiza la varianza. Proyecta sus datos originales en direcciones que maximizan la varianza.\n",
    "    \n",
    "1.2 La proyección de los datos que realiza PCA se hace buscando minimizar o maximizar algo? Explique.\n",
    "\n",
    "R/: Maximizar la varianza total, para esa forma las variables que no aportan informacion significativa, ejemplo en el caso de tener una regresiaon donde maximizar la rianza cumple el mismi objetivo de minimizar el ECM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "En la siguiente celda, complete el código donde le sea indicado. Consulte la documentación oficial de la librería mlxtend para los métodos de extracción de características. https://rasbt.github.io/mlxtend/user_guide/feature_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación aplicando extracción: 0.07430463282841704 +/- 0.04391645244688941\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 92.5695367171583%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.37587642669677734 segundos.\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction Function\n",
    "#Recibe 2 parámetros: 1. el tipo de método de extracción (pca o lda como string), 2. el número componentes (para pca)\n",
    "#o el número de discriminantes (para lda)\n",
    "\n",
    "#Para este laboratorio solo se le pedirá trabajar con PCA, LDA es opcional.\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(tipo, n):\n",
    "    if tipo == 'pca':\n",
    "        ext = PCA(n_components=n)\n",
    "        return ext\n",
    "    elif tipo == 'lda':\n",
    "        ext = LDA(n_discriminants=n)\n",
    "        return ext\n",
    "    else:\n",
    "        print (\"Ingrese un método válido (pca o lda)\\n\")\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Estandarizamos los datos\n",
    "X = standardize(X)\n",
    "\n",
    "#Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    #Aquí se aplica la extracción de características por PCA\n",
    "    #Complete el código\n",
    "    #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "    ex = extract_features('pca',21)\n",
    "\n",
    "    #Fit de PCA\n",
    "    #Complete el código con el fit correspondiente\n",
    "    ex = ex.fit(X)\n",
    "    \n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    #complete el código aquí para hacer la transformación\n",
    "    X_ex = ex.transform(X)\n",
    "    \n",
    "    \n",
    "    #Aquí se aplica la extracción de características por LDA\n",
    "    \n",
    "    #OPCIONAL\n",
    "    '''\n",
    "    ex = #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "\n",
    "    #Fit de LDA\n",
    "    ex = #Complete el código con el fit correspondiente\n",
    "    \n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    X_ex = #complete el código aquí para hacer la transformación\n",
    "    '''\n",
    "    \n",
    "    #Se aplica CV-10\n",
    "    \n",
    "    X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "   \n",
    "    #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "        \n",
    "\n",
    "print(\"\\nError de validación aplicando extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print(\"\\nEficiencia en validación aplicando extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "\n",
    "print ((\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i)) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "3.1 En la celda de código anterior, varíe los parámetros correspondientes al número de componentes principales a tener en cuenta (use 2, 10, 19 y 21 componentes principales) para PCA y complete la siguiente tabla de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d0200e21444fa69d6b7e9f99d3a92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "df_types = pd.DataFrame({\n",
    "    'Técnica' : pd.Series(['SVM sin extracción','SVM + PCA','SVM + PCA','SVM + PCA','SVM + PCA']),\n",
    "    '# Componentes principales' : pd.Series(['N/A', 2,10,19,21])})\n",
    "df_types[\"Error de Validación\"] = \"\"\n",
    "df_types[\"Intervalo de confianza (std)\"] = \"\"\n",
    "df_types[\"Eficiencia en validación\"] = \"\"\n",
    "df_types[\"Tiempo de ejecución\"] = \"\"\n",
    "df_types.set_index(['Técnica','# Componentes principales'], inplace=True)\n",
    "#df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error de Validación</th>\n",
       "      <th>Intervalo de confianza (std)</th>\n",
       "      <th>Eficiencia en validación</th>\n",
       "      <th>Tiempo de ejecución</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Técnica</th>\n",
       "      <th># Componentes principales</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM sin extracción</th>\n",
       "      <th>N/A</th>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>92.6636</td>\n",
       "      <td>0.39s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">SVM + PCA</th>\n",
       "      <th>2</th>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>77.8572</td>\n",
       "      <td>0.62s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.061</td>\n",
       "      <td>90.8306</td>\n",
       "      <td>0.59s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>92.8060</td>\n",
       "      <td>0.40s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>92.5695</td>\n",
       "      <td>0.39s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Error de Validación  \\\n",
       "Técnica            # Componentes principales                       \n",
       "SVM sin extracción N/A                                    0.0733   \n",
       "SVM + PCA          2                                      0.2214   \n",
       "                   10                                     0.0916   \n",
       "                   19                                     0.0719   \n",
       "                   21                                     0.0743   \n",
       "\n",
       "                                             Intervalo de confianza (std)  \\\n",
       "Técnica            # Componentes principales                                \n",
       "SVM sin extracción N/A                                             0.0435   \n",
       "SVM + PCA          2                                               0.1700   \n",
       "                   10                                               0.061   \n",
       "                   19                                              0.0484   \n",
       "                   21                                              0.0439   \n",
       "\n",
       "                                             Eficiencia en validación  \\\n",
       "Técnica            # Componentes principales                            \n",
       "SVM sin extracción N/A                                        92.6636   \n",
       "SVM + PCA          2                                          77.8572   \n",
       "                   10                                         90.8306   \n",
       "                   19                                         92.8060   \n",
       "                   21                                         92.5695   \n",
       "\n",
       "                                             Tiempo de ejecución  \n",
       "Técnica            # Componentes principales                      \n",
       "SVM sin extracción N/A                                     0.39s  \n",
       "SVM + PCA          2                                       0.62s  \n",
       "                   10                                      0.59s  \n",
       "                   19                                      0.40s  \n",
       "                   21                                      0.39s  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Analizando los resultados del punto anterior que puede decir de la viabilidad de aplicar PCA para hacer reducción de dimensión en este problema?\n",
    "\n",
    "R/: Utilizar PCA no es una mejora significativa en los resultados, esto se debe a que el set de datos no tiene una dimensionalidad muy alta, por lo cual los resultados de la PCA mejora cuando se acerca a la cantidad original de componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras la principal ventaja que tiene LDA sobre PCA para resolver problemas de clasificación.\n",
    "\n",
    "R/: Es supervisado, por lo cual tiene en cuenta las salidas del sisema y puede mejorar computacionalmente los resultados. Selecciona las caracteristicas que maximizan las separacion de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras las diferencias que existen entre los métodos de selección de características y los métodos de extracción de características vistos en el curso.\n",
    "\n",
    "R/: La selección como su nombre seleccionar (elimina, descarta)las características que explican la mayor parte de la variable objetivo (tiene una correlación con la variable objetivo). Esta prueba se ejecuta justo antes de que el modelo se aplique a los datos. En contraste la extracción hace una transformación sobre las caracteristicas, lo que puede  implicar una acción ireversible, ya que alguna información puede perderce en el proceso de reducción de dimensionalidad. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
